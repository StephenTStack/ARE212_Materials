{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Eleanor Adachi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Admin\n",
    "\n",
    "We created a fork of the main GitHub repository. Our code can be found here: https://github.com/eleanor-adachi/ARE212_Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercises\n",
    "\n",
    "### (1)\n",
    "\n",
    "From ARE210, recall (Section 9 in Mahajan’s “Handout 1”) the rule for computing the distribution of certain transformations\n",
    "of random variables (The “inverse Jacobian rule”). Let $(x, y)$ be independently distributed continuous random variables possessing densities $f_x$ and $f_y$. Let $z = x+y$. Use the rule to obtain an expression for the distribution of $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBD: Convolutions or SUR (Seemingly Unrelated Regressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simultaneous Equations\n",
    "\n",
    "When we defined the general weighted regression, we didn’t assume anything about the dimension of the different objects except that they were 'conformable.'\n",
    "\n",
    "So: consider\n",
    "\n",
    "(2) $y = X\\beta + u$; with $E[T'u] = 0$, and where $y = [y_1, y_2, ... , y_k]$, so that if you had a sample of N observations\n",
    "realizations of y would be an $N \\times k$ matrix.\n",
    "\n",
    "### (1)\n",
    "\n",
    "What does our assumption of conformability then imply about the dimensions of X, $\\beta$, T, and u?\n",
    "\n",
    "### (2)\n",
    "\n",
    "Could you use the estimator we developed in `weighted_regression.ipynb` to estimate this system of simultaneous equations?\n",
    "\n",
    "### (3)\n",
    "\n",
    "Extend the code in `weighted_regression.ipynb` to actually estimate $\\beta$ in the case with $k = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE copied from weighted_regression.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "k = 3 # Number of observables in T\n",
    "\n",
    "mu = [0]*k\n",
    "Sigma=[[1,0.5,0],\n",
    "       [0.5,2,0],\n",
    "       [0,0,3]]\n",
    "\n",
    "T = multivariate_normal(mu,Sigma)\n",
    "\n",
    "u = multivariate_normal(cov=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a sample of observables $(y,X,T)$ we just use the regression equation, plus an assumption about the value of $\\beta$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE copied from weighted_regression.ipynb\n",
    "\n",
    "beta = [1/2,1]\n",
    "\n",
    "D = np.random.random(size=(3,2)) # Generate random 3x2 matrix\n",
    "\n",
    "N=1000 # Sample size\n",
    "\n",
    "# Now: Transform rvs into a sample\n",
    "T = T.rvs(N)\n",
    "\n",
    "u = u.rvs(N) # Replace u with a sample\n",
    "\n",
    "X = (T**3)@D  # Note use of ** operator for exponentiation\n",
    "\n",
    "y = X@beta + u # Note use of @ operator for matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classical case we were trying to solve a linear system that took the form $Ab=0$, with $A$ a square matrix.  In the present case we're also trying to solve a linear system, but with a matrix $A$ that may have more rows than columns.  Provided the rows are linearly independent, this implies that we have an **overidentified** system of equations.  We'll return to the implications of this later, but for now this also calls for a different numerical approach, using `np.linalg.lstsq` instead of `np.linalg.solve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50914946 0.9853293 ]\n",
      "[[ 7.62518514e-05 -1.19992417e-04]\n",
      " [-1.19992417e-04  1.90769033e-04]]\n"
     ]
    }
   ],
   "source": [
    "# NOTE copied from weighted_regression.ipynb\n",
    "\n",
    "from scipy.linalg import inv, sqrtm\n",
    "\n",
    "b = np.linalg.lstsq(T.T@X,T.T@y,rcond=None)[0] # lstsq returns several results\n",
    "\n",
    "e = y - X@b\n",
    "\n",
    "print(b)\n",
    "\n",
    "TXplus = np.linalg.pinv(T.T@X) # Moore-Penrose pseudo-inverse\n",
    "\n",
    "# Covariance matrix of b\n",
    "vb = e.var()*TXplus@T.T@T@TXplus.T  # u is known to be homoskedastic\n",
    "\n",
    "print(vb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)\n",
    "\n",
    "What additional assumptions are necessary to estimate the distribution of the estimator of $\\beta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. “Plug-in” Kernel Bias Estimator\n",
    "\n",
    "In our discussion of bias of the kernel density estimator in lecture we constructed an “Oracle” estimator, which can be implemented when we know the true density $f$ that we’re trying to estimate.\n",
    "\n",
    "Of course, the Oracle estimator is only feasible when we don’t need it. What about the idea of using the same expression for bias as in the Oracle case, but replacing $f$ with our estimate $\\hat{f}$? Would this tell us anything useful? If so, under what conditions? What pitfalls might one encounter?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
